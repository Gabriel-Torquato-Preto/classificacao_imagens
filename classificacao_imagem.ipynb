{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Exemplo Classificação de Imagens"
      ],
      "metadata": {
        "id": "DwHdh86LVeKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste exemplo utilizaremos a biblioteca Tensorflow e Keras para montar um modelo de IA simples, voltada para classificação de imagens."
      ],
      "metadata": {
        "id": "H3tMgTpOWbdH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para iniciarmos primeiramente é necesária a instalação dessas duas bibliotecas."
      ],
      "metadata": {
        "id": "hqhujw6tXSvT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0yfVCds-L0D"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiramente precisamos importar os dados que usaremos para o treinamento de nossa IA, pra isso usaremos o dataset <a href=\"https://www.cs.toronto.edu/~kriz/cifar.html\">CIFAR-10</a>, que consiste de 60000 de 32x32 dividas em 10 classes(aviões, carros, passaros, gatos, cervos, cachorros, sapos, cavalos, návios e caminhões)."
      ],
      "metadata": {
        "id": "2D3FSIS4ZH3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "print(f\"X_train: {X_train.shape}\") # 50000, 32, 32, 3\n",
        "print(f\"y_train: {y_train.shape}\") # 50000, 1\n",
        "print(f\"X_test: {X_test.shape}\")   # 10000, 32, 32, 3\n",
        "print(f\"y_test: {y_test.shape}\")   # 10000, 1"
      ],
      "metadata": {
        "id": "HkhZUZZK-Nhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste trecho definimos as labels para as imagens e fazemos o usa da <a href=\"https://matplotlib.org/\">MatPlotLib</a> pra gerar um gráfico mostrando algumas imagens aleatórias apenas para demonstração."
      ],
      "metadata": {
        "id": "YkDT1iGq8Tga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "lbls = ['Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog',\n",
        "                'Frog', 'Horse', 'Ship', 'Truck']\n",
        "\n",
        "fig, axes = plt.subplots(5,5, figsize = (10,10))\n",
        "axes = axes.ravel()\n",
        "for i in np.arange(0, 5*5):\n",
        "    idx = np.random.randint(0, len(X_train))\n",
        "    axes[i].imshow(X_train[idx])\n",
        "    lbl_idx = int(y_train[idx][0])\n",
        "    axes[i].set_title(lbls[lbl_idx], fontsize = 8)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.subplots_adjust(hspace=0.4)"
      ],
      "metadata": {
        "id": "TW_UrPCy-_tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui um gráfico indicando a distribuição da quantidade de imagens de cada tipo de classe no dataset."
      ],
      "metadata": {
        "id": "jeVtrFdP9fQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes, counts = np.unique(y_train, return_counts=True)\n",
        "plt.barh(lbls, counts)\n",
        "plt.title('Class distribution in training set')"
      ],
      "metadata": {
        "id": "7UXJqnsp__-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesse bloco pegamos a quantidade de pixels de todas as imagens que geralmente, variam de 0 a 255 e dividimos por 255.0, isso faz com que esses valores escalem de 0 a 1, ajudando a otimizar o treinamento."
      ],
      "metadata": {
        "id": "nTkdmBae9-zK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "metadata": {
        "id": "Xja1YmfTAWdk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste trecho pegamos os arrays das labels das imagens e utilizamos <a href=\"https://www.geeksforgeeks.org/ml-one-hot-encoding/\">one-hot encoding</a> pra transformar essas labels em vetores binários."
      ],
      "metadata": {
        "id": "gfoTSmvyDhOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_cat = tf.keras.utils.to_categorical(y_train, 10)\n",
        "print(y_train_cat[:10])\n",
        "y_test_cat = tf.keras.utils.to_categorical(y_test, 10)\n",
        "print(\"\\n\")\n",
        "print(y_test_cat[:10])"
      ],
      "metadata": {
        "id": "xb8EVM_qApEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Na sequência pegamos os arrays com os dados de treinamento e fazemos uso da biblioteca <a href=\"https://scikit-learn.org/stable/index.html\">scikit-learn</a> para randomizar os dados."
      ],
      "metadata": {
        "id": "BoBDwzwhFgrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_TRAIN, X_VAL, Y_TRAIN, Y_VAL = train_test_split(X_train,\n",
        "                                                y_train_cat,\n",
        "                                                test_size=0.2,\n",
        "                                                random_state=42)"
      ],
      "metadata": {
        "id": "-v6__7C2Aw11"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora definimos quantas imagens serão preocessadas por vez durante o treinamento, nesse caso 64, e usamos a classe ImageDataGenerator, com a finalidade de flipar algumas imagens horizontalmente aleatoriamente, pra trazer mais diversidade de cenários durante o treinamento."
      ],
      "metadata": {
        "id": "kAwsGmSACFZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "batch_size = 64\n",
        "data_generator = ImageDataGenerator(horizontal_flip=True)\n",
        "\n",
        "train_generator = data_generator.flow(X_TRAIN, Y_TRAIN, batch_size)"
      ],
      "metadata": {
        "id": "Ao34fxfnA_TE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prosseguindo definimos o formato das imagens, 32 pixels de altura e largura e 3 canais de RGB. Setamos também as camadas de nossa IA, nesse exemplo usamos a classe Senquential, que é usada na construção de modelos de deep learning, permitindo adicionar múltiplas layers no modelo. Adicionamos 4 layers de <a href=\"https://www.geeksforgeeks.org/apply-a-2d-convolution-operation-in-pytorch/\">Conv2D</a> usando a função de ativação <a href=\"https://www.geeksforgeeks.org/relu-activation-function-in-deep-learning/\">Relu</a>, 4 layers de <a href=\"https://www.geeksforgeeks.org/what-is-batch-normalization-in-deep-learning/\">BatchNormalization</a>, 1 de <a href=\"https://towardsdatascience.com/dropout-in-neural-networks-47a162d621d9/\">Dropout</a>, 1 de <a href=\"https://deeplizard.com/learn/video/ZjM_XQa5s6s\">MaxPool2D</a>, 1 de <a href=\"https://nulldog.com/keras-flatten-explained-usage-and-purpose-in-neural-networks\">Flatten</a> e por fim 2 de <a href=\"https://iatracker.com.br/glossario/o-que-e-dense-layer/\">Dense</a> uma com a função de ativação relu e outra com <a href=\"https://www.geeksforgeeks.org/the-role-of-softmax-in-neural-networks-detailed-explanation-and-applications/\">Softmax</a>. Encerrando utilizamos a função summary para mostrar todas as layers do nosso modelo e a quantidade de parâmetros que ele ficou."
      ],
      "metadata": {
        "id": "BtndDQvsJXg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, Dropout, Flatten, Dense\n",
        "\n",
        "INPUT_SHAPE = (32, 32, 3)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16, kernel_size=(3, 3), input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=16, kernel_size=(3, 3), input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "YTfBgq9aBKD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depois definimos quais as métricas iremos usa. O <a href=\"https://www.geeksforgeeks.org/loss-functions-in-deep-learning/\">Loss</a> é uma função matemática que calcula o quanto nosso modelo é ruim fazendo predições, o <a href=\"https://www.geeksforgeeks.org/adam-optimizer/\">Adam</a> é uma função que serve para otimizar o treinamento ajustando alguns parâmetros automaticamente conforme o andamento do treinamento, também otimizando o uso de memória, por fim o accuracy é a porcentagem de acerto nas predições."
      ],
      "metadata": {
        "id": "AhByTq9JDkht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "               optimizer='adam',\n",
        "               metrics=['accuracy']\n",
        "              )"
      ],
      "metadata": {
        "id": "Uny2dEfwBUNF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por fim, damos inicío ao treinamento, passando as imagens que preparamos, em quantas epochs será feito, e as imagens originais para validação."
      ],
      "metadata": {
        "id": "nPd9Q-k2RciM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs=10,\n",
        "                    validation_data=(X_VAL, Y_VAL),\n",
        "                    )"
      ],
      "metadata": {
        "id": "gmrUB6xEBeUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 16))\n",
        "\n",
        "plt.subplot(4, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.plot(history.history['val_loss'], label='val_Loss')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(4, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "ReIoCkeICAvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "con = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=lbls)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "con = con.plot(xticks_rotation='vertical', ax=ax,cmap='summer')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1k_A8eeOCG_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "idx = random.randint(0, len(X_test))\n",
        "im = X_test[idx]\n",
        "plt.imshow(im)\n",
        "\n",
        "pred_t = np.argmax(model.predict(im.reshape(1, 32, 32, 3)))\n",
        "print(pred_t)\n",
        "print(f\"our model predicts that image {idx} is {lbls[pred_t]}\")"
      ],
      "metadata": {
        "id": "h5gNPZTFCTaU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}